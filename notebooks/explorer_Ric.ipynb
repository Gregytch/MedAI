{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_pred = pd.read_csv(\"../raw_data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseases</th>\n",
       "      <th>anxiety and nervousness</th>\n",
       "      <th>depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         diseases  anxiety and nervousness  depression\n",
       "0  panic disorder                        1           0\n",
       "1  panic disorder                        0           0\n",
       "2  panic disorder                        1           1\n",
       "3  panic disorder                        1           0\n",
       "4  panic disorder                        1           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_pred.iloc[0:10, 0:3]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dictionary at: /home/ricardasch/code/Gregytch/MedAI/notebooks/frequency_dictionary_en_82_765.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dictionary_path = os.path.abspath(\"frequency_dictionary_en_82_765.txt\")\n",
    "print(f\"Using dictionary at: {dictionary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<symspellpy.suggest_item.SuggestItem object at 0x7f8f13932e00>]\n",
      "head ache\n",
      "[<symspellpy.suggest_item.SuggestItem object at 0x7f8f13933100>]\n",
      "headache\n",
      "[<symspellpy.suggest_item.SuggestItem object at 0x7f8f13932e00>]\n",
      "hypertension\n",
      "[<symspellpy.suggest_item.SuggestItem object at 0x7f8f13933100>]\n",
      "headache\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "# Initialize SymSpell\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2)\n",
    "\n",
    "# Load a frequency dictionary\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "# Correct typos\n",
    "input_texts = [\"head ache\", \"headache\", \"hypertenssion\", \"eadache\"]\n",
    "for element in input_texts:\n",
    "    suggestion = sym_spell.lookup_compound(element, max_edit_distance=2)\n",
    "    print(suggestion[0].term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diseases': 'panic disorder', 'anxiety and nervousness': 1, 'depression': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246945"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_pred.diseases.unique())\n",
    "len(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.34699693920182)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred.drop(columns = \"diseases\").mean().mean()*378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming text input to required vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['headache', 'nauseous', 'nervousness', 'shaking', 'fever']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"headache, nauseous, nervousness, shaking, fever\"\n",
    "symptoms = [\"headache\", \"nauseousness\", \"anxiety\", \"tremors\"]\n",
    "\n",
    "text_tokens = text.split(\",\")\n",
    "text_tokens = [a.strip() for a in text_tokens]\n",
    "text_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardasch/.pyenv/versions/3.10.6/envs/MedAI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-distilroberta-base-v2')\n",
    "embeddings_data = model.encode(symptoms)\n",
    "embeddings_input = model.encode(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "similiarities = np.zeros(shape = (4, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.3025, 0.2897, 0.0522]])\n",
      "tensor(0)\n",
      "headache matches headache with probability 1.0000001192092896\n",
      "tensor([[0.3083, 0.9660, 0.4806, 0.0711]])\n",
      "tensor(1)\n",
      "nauseous matches nauseousness with probability 0.9660372734069824\n",
      "tensor([[0.2599, 0.6796, 0.5883, 0.1451]])\n",
      "tensor(1)\n",
      "nervousness matches nauseousness with probability 0.6796494126319885\n",
      "tensor([[0.1316, 0.1603, 0.1361, 0.1714]])\n",
      "tensor(3)\n",
      "shaking matches tremors with probability 0.17139729857444763\n",
      "tensor([[0.1896, 0.1592, 0.1380, 0.2380]])\n",
      "tensor(3)\n",
      "fever matches tremors with probability 0.23804573714733124\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# Compute cosine similarity\n",
    "for i in range(len(text_tokens)):\n",
    "    cosine_scores = util.cos_sim(embeddings_input[i], embeddings_data)\n",
    "    print(cosine_scores)\n",
    "    print(np.argmax(cosine_scores))\n",
    "    print(f\"{text_tokens[i]} matches {symptoms[np.argmax(cosine_scores)]} with probability {cosine_scores.max()}\")\n",
    "\n",
    "# # Get the most similar symptoms\n",
    "# top_matches = sorted(enumerate(cosine_scores[0]), key=lambda x: x[1], reverse=True)\n",
    "# for idx, score in top_matches[:5]:\n",
    "#     print(f\"Match: {symptoms_list[idx]} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in len(text_tokens):\n",
    "    liste = []\n",
    "    for b in len(symptoms):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7\n",
       "0  0  0  0  1  1  0  1  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.randint(0,2, size=(1,8)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    1\n",
       "2    3\n",
       "3    1\n",
       "4    6\n",
       "5    4\n",
       "6    3\n",
       "7    8\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7\n",
      "0  1  0  0  0  0  1  1  0\n",
      "https://disease-predictor-vol2-739437866088.europe-west1.run.app/predict_disease\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result1': 'Here is prediction 1: 3', 'result2': 'Here is prediction2: 0.375'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "df = pd.DataFrame(np.random.randint(0,2, size=(1,8)))\n",
    "print(df)\n",
    "url = 'https://disease-predictor-vol2-739437866088.europe-west1.run.app/predict_disease'\n",
    "df_dict = {\"data\": df.to_dict(orient=\"records\")}\n",
    "res = requests.post(url, json=df_dict)\n",
    "print(res.url)\n",
    "res.json()\n"
   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [

    "import requests\n",
    "\n",
    "symptoms = \"fever, headache, sore throat, sore muscles, tirehd\"\n",
    "url = 'http://127.0.0.1:8000/diagnosis'\n",
    "params = {\"inputs\": symptoms}\n",
    "res = requests.get(url, params = params)\n",
    "res.json()"
=======
    "res.json()\n"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_creator(text, data):\n",
    "    model = SentenceTransformer('sentence-transformers/paraphrase-distilroberta-base-v2')\n",
    "    #Load Model from pickle\n",
    "    #model = load_nlp_model()\n",
    "\n",
    "    #prepare\n",
    "    data = data\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    #tokenizer\n",
    "    symptoms = text.split(\",\")\n",
    "    symptoms = [a.strip() for a in symptoms]\n",
    "\n",
    "    #embeddings\n",
    "    embeddings_symptoms = model.encode(symptoms)\n",
    "    embeddings_columns = model.encode(columns)\n",
    "\n",
    "    #similarities\n",
    "    similiarities = np.zeros(shape = (len(columns), len(symptoms)))\n",
    "\n",
    "    #Setup output file\n",
    "    zero_data = np.zeros(shape=(1, len(columns)))\n",
    "    vector = pd.DataFrame(zero_data, columns=columns)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    for i in range(len(symptoms)):\n",
    "        cosine_scores = util.cos_sim(embeddings_symptoms[i], embeddings_columns)\n",
    "        print(f\"{symptoms[i]} matches {columns[np.argmax(cosine_scores)]} with probability {cosine_scores.max()}\")\n",
    "        vector[columns[np.argmax(cosine_scores)]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_pred = pd.read_csv(\"../raw_data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m NLP_MODEL_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../models/NLP_bio_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m COL_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../models/dataset_col.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "dir=os.path.dirname(__file__)\n",
    "NLP_MODEL_PATH = os.path.join(dir, \"../../models/NLP_bio_model.pkl\")\n",
    "COL_PATH = os.path.join(dir, \"../../models/dataset_col.pkl\")\n",
    "\n",
    "#get data\n",
    "with open(NLP_MODEL_PATH, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "with open(COL_PATH, \"rb\") as f:\n",
    "    columns = pickle.load(f)\n",
    "\n",
    "embeddings_columns = model.encode(columns)\n",
    "\n",
    "with open(os.path.join(dir,\"../../models/embeddings_columns.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(embeddings_columns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = \"headache, bad fever, rash, nauseous, pressure on the eye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "def input_creator_med(text, data):\n",
    "    model = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')\n",
    "    #Load Model from pickle\n",
    "    #model = load_nlp_model()\n",
    "\n",
    "    #prepare\n",
    "    data = data\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    #tokenizer\n",
    "    symptoms = text.split(\",\")\n",
    "    symptoms = [a.strip() for a in symptoms]\n",
    "\n",
    "    #embeddings\n",
    "    embeddings_symptoms = model.encode(symptoms)\n",
    "    embeddings_columns = model.encode(columns)\n",
    "\n",
    "    #similarities\n",
    "    similiarities = np.zeros(shape = (len(columns), len(symptoms)))\n",
    "\n",
    "    #Setup output file\n",
    "    zero_data = np.zeros(shape=(1, len(columns)))\n",
    "    vector = pd.DataFrame(zero_data, columns=columns)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    for i in range(len(symptoms)):\n",
    "        cosine_scores = util.cos_sim(embeddings_symptoms[i], embeddings_columns)\n",
    "        print(f\"{symptoms[i]} matches {columns[np.argmax(cosine_scores)]} with probability {cosine_scores.max()}\")\n",
    "        vector[columns[np.argmax(cosine_scores)]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headache matches headache with probability 1.0000001192092896\n",
      "bad fever matches feeling ill with probability 0.5291414260864258\n",
      "rash matches skin rash with probability 0.2823391258716583\n",
      "nauseous matches nausea with probability 0.8684877157211304\n",
      "pressure on the eye matches pain in eye with probability 0.7268694639205933\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector1 = input_creator(ex1, data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headache matches headache with probability 1.0000001192092896\n",
      "bad fever matches fever with probability 0.8296034932136536\n",
      "rash matches skin rash with probability 0.9113404154777527\n",
      "nauseous matches nasal congestion with probability 0.47669023275375366\n",
      "pressure on the eye matches eye strain with probability 0.7148137092590332\n"
     ]
    }
   ],
   "source": [
    "vector2 = input_creator_med(ex1, data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardasch/.pyenv/versions/3.10.6/envs/MedAI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pickle\n",
    "with open(\"NLP_bio_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb'), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# columns = list(columns)\n",
    "# columns.remove(\"diseases\")\n",
    "# columns\n",
    "with open(\"dataset_col.pkl\", \"wb\") as f:\n",
    "    pickle.dump(columns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TF-IDF model\n",
    "with open(\"NLP_bio_model.pkl\", \"rb\") as f:\n",
    "    loaded_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_symptoms = loaded_vectorizer.encode([\"fever\", \"sneeze\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file\u001b[38;5;241m=\u001b[39m\u001b[38;5;18;43m__file__\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(file)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load data from directory (relative path)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "df_symp = pd.read_csv(pd.read_csv(\"../raw_data/Final_Augmented_dataset_Diseases_and_Symptoms.csv\"))\n",
    "\n",
    "#Clean the data calling the function clean_data\n",
    "data=clean_data(df_symp)\n",
    "\n",
    "#Creating X and y\n",
    "X=data.drop(['diseases'], axis=1)\n",
    "X.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
